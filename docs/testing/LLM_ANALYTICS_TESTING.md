# üß™ LLM & Analytics Layer Testing Guide

## Testing IBM watsonx Orchestrate Agent - LLM & Analytics Features

This guide provides specific test queries to verify that your deployed agent is using:
- **watsonx.ai (Granite models)** - LLM reasoning and predictions
- **NLU** - Sentiment analysis and emotion detection
- **Sentiment Classifier** - Risk assessment
- **Forecasting Models** - Trend predictions

---

## üåê Access Your Agent

**Web UI:** https://au-syd.watson-orchestrate.cloud.ibm.com/build/manage

1. Go to "All agents"
2. Click on "ProActive_CSI_Agent_404"
3. Use the chat interface to test

---

## üß™ Test Category 1: watsonx.ai (Granite Models) Testing

These queries test the LLM's reasoning, prediction, and content generation capabilities.

### Test 1.1: Churn Prediction Using watsonx.ai
```
Query: "Predict churn probability for customer C-003 TechGlobal Inc using watsonx.ai models"

Expected Response Should Include:
‚Ä¢ Churn probability score (0-100%)
‚Ä¢ Mention of watsonx.ai prediction model
‚Ä¢ Risk level classification
‚Ä¢ Model confidence/accuracy metrics
```

### Test 1.2: AI-Powered Recommendations
```
Query: "Generate AI-powered intervention recommendations for customer C-001 Acme Corp"

Expected Response Should Include:
‚Ä¢ Personalized recommendations
‚Ä¢ Mention of watsonx.ai recommendation engine
‚Ä¢ Intervention strategy
‚Ä¢ Expected ROI/impact
```

### Test 1.3: Content Generation
```
Query: "Generate a renewal brief for customer C-005 DataSystems using AI"

Expected Response Should Include:
‚Ä¢ Personalized renewal brief
‚Ä¢ Generated by watsonx.ai
‚Ä¢ Customized content based on customer history
‚Ä¢ Executive summary
```

### Test 1.4: Financial Forecasting
```
Query: "Forecast revenue at risk for the next quarter using watsonx.ai forecasting models"

Expected Response Should Include:
‚Ä¢ Quarterly revenue forecast
‚Ä¢ Trend analysis
‚Ä¢ Best case / worst case / most likely scenarios
‚Ä¢ Forecasting model predictions
```

### Test 1.5: Health Score Calculation
```
Query: "Calculate customer health score for C-008 CloudVenture using watsonx.ai models"

Expected Response Should Include:
‚Ä¢ Health score (0-100)
‚Ä¢ Factors contributing to score
‚Ä¢ watsonx.ai model analysis
‚Ä¢ Recommendation based on score
```

---

## üß™ Test Category 2: NLU (Natural Language Understanding) Testing

These queries test sentiment analysis, emotion detection, and keyword extraction.

### Test 2.1: Sentiment Analysis
```
Query: "Analyze sentiment of customer communication: 'We are reconsidering our renewal. The service delays have been unacceptable and we're frustrated.'"

Expected Response Should Include:
‚Ä¢ Sentiment label (positive/negative/neutral)
‚Ä¢ Sentiment score (-1 to +1)
‚Ä¢ Emotion detection (frustration, disappointment, etc.)
‚Ä¢ Risk level assessment
```

### Test 2.2: Customer Communication Sentiment
```
Query: "What's the sentiment of recent communications from customer C-003 TechGlobal Inc?"

Expected Response Should Include:
‚Ä¢ Sentiment analysis results
‚Ä¢ NLU sentiment classification
‚Ä¢ Emotion breakdown
‚Ä¢ Risk signals detected
‚Ä¢ Keywords extracted
```

### Test 2.3: Support Ticket Sentiment
```
Query: "Analyze sentiment of support tickets for customer C-001 Acme Corp using NLU"

Expected Response Should Include:
‚Ä¢ Overall sentiment score
‚Ä¢ Individual ticket sentiment
‚Ä¢ Emotion analysis
‚Ä¢ Risk keywords detected
‚Ä¢ NLU-powered classification
```

### Test 2.4: Email Sentiment Analysis
```
Query: "Analyze this customer email sentiment: 'I'm very disappointed with the recent vendor delays. We might need to look at alternatives.'"

Expected Response Should Include:
‚Ä¢ Negative sentiment detection
‚Ä¢ High risk classification
‚Ä¢ Keywords: "disappointed", "delays", "alternatives"
‚Ä¢ Recommended action
‚Ä¢ NLU analysis details
```

### Test 2.5: Multi-Customer Sentiment Comparison
```
Query: "Compare sentiment trends across all critical customers using NLU"

Expected Response Should Include:
‚Ä¢ Sentiment trends for each customer
‚Ä¢ NLU-powered analysis
‚Ä¢ Risk level comparisons
‚Ä¢ Trend visualization/data
```

---

## üß™ Test Category 3: Sentiment Classifier Testing

These queries test the risk classification and sentiment-based categorization.

### Test 3.1: Risk Level Classification
```
Query: "Classify risk level for customer C-003 TechGlobal Inc based on sentiment analysis"

Expected Response Should Include:
‚Ä¢ Risk level (LOW/MEDIUM/HIGH/CRITICAL)
‚Ä¢ Classification based on sentiment
‚Ä¢ Sentiment classifier results
‚Ä¢ Confidence score
```

### Test 3.2: Customer Risk Categorization
```
Query: "Categorize all customers by risk level using sentiment classifier"

Expected Response Should Include:
‚Ä¢ Customers grouped by risk level
‚Ä¢ Sentiment-based classification
‚Ä¢ Count of customers per category
‚Ä¢ Priority ranking
```

### Test 3.3: Sentiment-Driven Alerts
```
Query: "Show customers that need immediate attention based on negative sentiment"

Expected Response Should Include:
‚Ä¢ Customers with negative sentiment
‚Ä¢ Sentiment classifier flags
‚Ä¢ Alert priority
‚Ä¢ Recommended interventions
```

---

## üß™ Test Category 4: Forecasting Models Testing

These queries test trend prediction and forecasting capabilities.

### Test 4.1: Churn Trend Forecasting
```
Query: "Forecast churn trend for the next 90 days using forecasting models"

Expected Response Should Include:
‚Ä¢ Churn trend forecast
‚Ä¢ Time-series predictions
‚Ä¢ Risk curve projection
‚Ä¢ Forecasting model output
```

### Test 4.2: Revenue Forecasting
```
Query: "Forecast ARR at risk for the next quarter using predictive models"

Expected Response Should Include:
‚Ä¢ Quarterly ARR forecast
‚Ä¢ Revenue trend analysis
‚Ä¢ Best/worst case scenarios
‚Ä¢ Forecasting model predictions
```

### Test 4.3: Customer Health Trend
```
Query: "Predict customer health trend for C-001 Acme Corp over next 60 days"

Expected Response Should Include:
‚Ä¢ Health trend projection
‚Ä¢ Forecasted risk trajectory
‚Ä¢ Intervention impact prediction
‚Ä¢ Trend analysis
```

### Test 4.4: Procurement Risk Forecasting
```
Query: "Forecast procurement delays and customer impact for next month"

Expected Response Should Include:
‚Ä¢ Delay probability forecast
‚Ä¢ Affected customer predictions
‚Ä¢ Revenue impact forecast
‚Ä¢ Trend analysis
```

### Test 4.5: Renewal Probability Forecasting
```
Query: "Forecast contract renewal probability for all customers using predictive models"

Expected Response Should Include:
‚Ä¢ Renewal probability for each customer
‚Ä¢ Forecasting model output
‚Ä¢ Trend indicators
‚Ä¢ Revenue protection forecast
```

---

## üîÑ Combined Feature Testing

### Test 5.1: Full Workflow with All Analytics
```
Query: "Run churn prediction workflow for C-003 TechGlobal Inc with full analytics"

Expected Response Should Include:
‚Ä¢ watsonx.ai churn prediction
‚Ä¢ NLU sentiment analysis
‚Ä¢ Sentiment classifier risk level
‚Ä¢ Forecasting trend projection
‚Ä¢ Comprehensive analytics summary
```

### Test 5.2: Executive Brief with Analytics
```
Query: "Generate executive brief with churn predictions, sentiment analysis, and revenue forecasts"

Expected Response Should Include:
‚Ä¢ watsonx.ai predictions
‚Ä¢ NLU sentiment analysis
‚Ä¢ Forecasting model results
‚Ä¢ Comprehensive analytics dashboard
‚Ä¢ Action recommendations
```

### Test 5.3: Customer Health Deep Dive
```
Query: "Provide complete analytics for customer C-001: predictions, sentiment, and forecasts"

Expected Response Should Include:
‚Ä¢ watsonx.ai health score
‚Ä¢ NLU sentiment breakdown
‚Ä¢ Sentiment classifier assessment
‚Ä¢ Forecasted trends
‚Ä¢ All analytics integrated
```

---

## ‚úÖ Verification Checklist

After testing, verify your agent is using:

### watsonx.ai (Granite Models)
- [ ] Churn predictions mention watsonx.ai or Granite models
- [ ] Recommendations are AI-generated
- [ ] Health scores calculated using ML models
- [ ] Content generation (briefs, emails) uses AI

### NLU (Natural Language Understanding)
- [ ] Sentiment scores provided (-1 to +1)
- [ ] Emotion detection (frustration, disappointment, etc.)
- [ ] Keywords extracted from text
- [ ] Risk signals identified from language

### Sentiment Classifier
- [ ] Risk levels classified (LOW/MEDIUM/HIGH/CRITICAL)
- [ ] Customers categorized by sentiment
- [ ] Alerts generated from sentiment analysis

### Forecasting Models
- [ ] Trend predictions provided
- [ ] Future scenarios (best/worst case)
- [ ] Time-series forecasts
- [ ] Probability estimates

---

## üéØ Expected Response Patterns

### When watsonx.ai is Working:
- Agent mentions "watsonx.ai", "AI model", "ML prediction", "Granite model"
- Provides probabilistic predictions (percentages)
- Generates content (briefs, recommendations)
- Shows confidence scores

### When NLU is Working:
- Agent mentions "sentiment analysis", "NLU", "sentiment score"
- Provides sentiment labels (positive/negative/neutral)
- Shows emotion breakdown
- Extracts keywords and risk phrases

### When Sentiment Classifier is Working:
- Agent categorizes risk levels
- Groups customers by sentiment
- Flags high-risk communications
- Prioritizes based on classification

### When Forecasting is Working:
- Agent provides future predictions
- Shows trend projections
- Gives scenario analysis
- Includes time-based forecasts

---

## üìä Sample Test Results to Look For

### Successful watsonx.ai Response:
```
ü§ñ Using watsonx.ai churn prediction model...
Churn Probability: 85% (watsonx.ai prediction)
Model Confidence: 89%
Risk Level: CRITICAL
```

### Successful NLU Response:
```
üß† NLU Sentiment Analysis:
Sentiment: Negative (-0.72)
Emotions: Frustration (0.65), Disappointment (0.58)
Keywords: "reconsidering", "unacceptable", "delays"
Risk Level: HIGH
```

### Successful Forecasting Response:
```
üìà Forecasting Model Prediction:
90-Day Churn Trend: Increasing (65% ‚Üí 78% ‚Üí 85%)
Revenue at Risk (Q1): $152,000 - $198,000
Forecast Confidence: 87%
```

---

## üîß Troubleshooting

### If watsonx.ai Not Mentioned:
- Verify LLM model is configured correctly
- Check agent instructions mention watsonx.ai
- Test simpler queries first

### If NLU Not Working:
- Verify NLU credentials are correct
- Check agent instructions include NLU workflow
- Test direct sentiment analysis queries

### If Forecasting Not Appearing:
- Ensure forecasting models are mentioned in agent instructions
- Test trend prediction queries
- Verify agent has access to historical data

---

## üöÄ Quick Test Commands

Copy-paste these directly into the chat:

```
1. "Predict churn for C-003 using watsonx.ai"

2. "Analyze sentiment of this text: 'We're very frustrated with the delays'"

3. "Classify risk level for all customers using sentiment"

4. "Forecast revenue at risk for next quarter"

5. "Generate AI-powered recommendations for C-001"

6. "Run full analytics workflow with all features"
```

---

**Last Updated:** 2025-01-XX  
**Agent Version:** v1.0.0  
**Testing Status:** Ready ‚úÖ

